--- 
## Semi-Supervised, UN-supervised, and self-supervised Object Detection


### ArXiv 2022  

+ Sparsely Annotated Object Detection: A Region-based Semi-supervised Approach  
Sai Saketh Rambhatla, Saksham Suri, Rama Chellappa, Abhinav Shrivastava  
[[paper](https://arxiv.org/pdf/2201.04620)] 

### CVPR 2019  
+ One pixel attack for fooling deep neural networks (One_Pixel_Attack)
Jiawei Su, Danilo Vasconcellos Vargas, Sakurai Kouichi
[[paper](https://arxiv.org/pdf/1710.08864.pdf)] [[code](https://github.com/sarathknv/adversarial-examples-pytorch/tree/master/one_pixel_attack)]

+ Improving Transferability of Adversarial Examples with Input Diversity (DI-FGSM)
Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou Ren, Alan Yuille
[[paper](https://arxiv.org/pdf/1803.06978.pdf)] [[code](https://github.com/cihangxie/DI-2-FGSM)]

+ Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks (TI-FGSM)
Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu
[[paper](https://arxiv.org/pdf/1904.02884.pdf)] [[code](https://github.com/dongyp13/Translation-Invariant-Attacks)]


### CVPR 2018  
+ Boosting Adversarial Attacks with Momentum (MI-FGSM)
Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, Jianguo Li
[[paper](https://arxiv.org/pdf/1705.07204.pdf)] [[code](https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks)]

### ICLR 2018  
+ Ensemble Adversarial Training: Attacks and Defenses
Florian Tram√®r, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel
[[paper](https://arxiv.org/pdf/1705.07204.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.rfgsm)]

+ Towards Deep Learning Models Resistant to Adversarial Attacks (PGD)
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu
[[paper](https://arxiv.org/pdf/1706.06083.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.pgd)]

### ICLR 2017  
+ ADVERSARIAL EXAMPLES IN THE PHYSICAL WORLD (BIM)
Alexey Kurakin, Ian Goodfellow, Samy Bengio  
[[paper](https://arxiv.org/pdf/1607.02533.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.bim)]

### S&P 2017(Best Student Paper)  
+ Towards Evaluating the Robustness of Neural Networks (C&W)
Nicholas Carlini, David Wagner
[[paper](https://arxiv.org/pdf/1608.04644.pdf)] [[code](https://github.com/carlini/nn_robust_attacks)]

### CVPR 2016  
+ DeepFool: a simple and accurate method to fool deep neural networks (Deepfool)
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard
[[paper](https://arxiv.org/pdf/1511.04599.pdf)] [[code](https://github.com/lts4/deepfool)]

### ICLR 2015  
+ EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES (FGSM)
Ian J. Goodfellow, Jonathon Shlens & Christian Szegedy  
[[paper](https://arxiv.org/pdf/1412.6572.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.fgsm)]
