

# Image Adversarial Attack
----
1.[Image_Adversarial_Example_Attack](#jump1)  
2.[Image_Adversarial_Patch_Attack](#jump2)  


---
## <span id="jump1">Image_Adversarial_Example_Attack</span>

### ArXiv 2022

+ Fast Gradient Non-sign Methods  
Yaya Cheng, Jingkuan Song, Xiaosu Zhu, Qilong Zhang, Lianli Gao, Heng Tao Shen  
[[paper](https://arxiv.org/pdf/2110.12734.pdf)] [[code](https://github.com/yaya-cheng/FGNM)]  

+ Improving the Transferability of Adversarial Examples with Restructure Embedded Patches  
Huipeng Zhou, Yu-an Tan, Yajie Wang, Haoran Lyu, Shangbo Wu, Yuanzhang Li  
[[paper](https://arxiv.org/pdf/2204.12680.pdf)] [[code]()]  

+ Improving Adversarial Transferability with Spatial Momentum  
Guoqiu Wang, Xingxing Wei, Huanqian Yan  
[[paper](https://arxiv.org/pdf/2203.13479.pdf)] [[code](https://github.com/yaya-cheng/FGNM)]  

+ Optimizing One-pixel Black-box Adversarial Attacks    
Tianxun Zhou, Shubhankar Agrawal, Prateek Manocha  
[[paper](https://arxiv.org/pdf/2205.02116.pdf)] [[code]()]

### ICLR 2022

+ Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?  
Yonggan Fu, Shunyao Zhang, Shang Wu, Cheng Wan, Yingyan Lin  
[[paper](https://arxiv.org/pdf/2203.08392.pdf)] [[code](https://github.com/rice-eic/patch-fool)]

### CVPR 2022

+ LAS-AT: Adversarial Training with Learnable Attack Strategy  
Xiaojun Jia, Yong Zhang, Baoyuan Wu, Ke Ma, Jue Wang, Xiaochun Cao  
[[paper](https://arxiv.org/pdf/2203.06616.pdf)] [[code](https://github.com/jiaxiaojunQAQ/LAS-AT)]

+ Boosting Black-Box Attack with Partially Transferred Conditional Adversarial Distribution  
Yan Feng, Baoyuan Wu, Yanbo Fan, Li Liu, Zhifeng Li, Shutao Xia  
[[paper](https://arxiv.org/pdf/2203.06616.pdf)] [[code](https://github.com/Kira0096/CGATTACK)]

+ Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting the Adversarial Transferability  
Yifeng Xiong, Jiadong Lin, Min Zhang, John E. Hopcroft, Kun He  
[[paper](https://arxiv.org/pdf/2111.10752.pdf)] [[code](https://github.com/jhl-hust/svre)]  

+ Towards Practical Certifiable Patch Defense with Vision Transformer  
Zhaoyu Chen, Bo Li, Jianghe Xu, Shuang Wu, Shouhong Ding, Wenqiang Zhang  
[[paper](https://arxiv.org/pdf/2203.08519.pdf)] [[code]()]  

+ Improving the Transferability of Targeted Adversarial Examples through Object-Based Diverse Input  
Junyoung Byun, Seungju Cho, Myung-Joon Kwon, Hee-Seon Kim, Changick Kim  
[[paper](https://arxiv.org/pdf/2203.09123.pdf)] [[code](https://github.com/dreamflake/odi)]

### CVPR 2021

+ Improving the Transferability of Adversarial Samples With Adversarial Transformations  
Weibin Wu, Yuxin Su, Michael R. Lyu, Irwin King  
[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Improving_the_Transferability_of_Adversarial_Samples_With_Adversarial_Transformations_CVPR_2021_paper.pdf)] [[code](https://github.com/sarathknv/adversarial-examples-pytorch/tree/master/one_pixel_attack)]

+ Enhancing the Transferability of Adversarial Attacks through Variance Tuning  
Xiaosen Wang, Kun He  
[[paper](https://arxiv.org/pdf/2103.15571.pdf)] [[code](https://github.com/JHL-HUST/VT)]

+ Transferable Sparse Adversarial Attack  
Ziwen He, Wei Wang, Jing Dong, Tieniu Tan  
[[paper](https://arxiv.org/pdf/2105.14727.pdf)] [[code](https://github.com/shaguopohuaizhe/TSAA)]

+ SurFree: a fast surrogate-free black-box attack  
Thibault Maho, Teddy Furon, Erwan Le Merrer  
[[paper](https://arxiv.org/pdf/2011.12807v1.pdf)] [[code](https://github.com/t-maho/SurFree)]

+ Natural Adversarial Examples  
Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, Dawn Song  
[[paper](https://arxiv.org/pdf/1907.07174.pdf)] [[code](https://github.com/hendrycks/natural-adv-examples)]

### IJCAI 2021

+ Demiguise Attack: Crafting Invisible Semantic Adversarial Perturbations with Perceptual Similarity  
Yajie Wang,Shangbo Wu,Wenyi Jiang,Shengang Hao,Yu-an Tan,Quanxin Zhang  
[[paper](https://www.ijcai.org/proceedings/2021/0430.pdf)] [[code]()]

### ICCV 2021

+ Attack Agnostic Detection of Adversarial Examples via Random Subspace Analysis (Defense)  
Nathan Drenkow, Neil Fendley, Philippe Burlina  
[[paper](https://arxiv.org/pdf/2012.06405.pdf)] [[code]()]  

+ Reliably fast adversarial training via latent adversarial perturbation (Defense)  
Geon Yeong Park Sang Wan Lee  
[[paper](Park_Reliably_Fast_Adversarial_Training_via_Latent_Adversarial_Perturbation_ICCV_2021_paper)] [[code]()]  

+ AGKD-BML: Defense Against Adversarial Attack by Attention Guided Knowledge Distillation and Bi-directional Metric Learning  
Hong Wang, Yuefan Deng, Shinjae Yoo, Haibin Ling, Yuewei Lin    
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_AGKD-BML_Defense_Against_Adversarial_Attack_by_Attention_Guided_Knowledge_Distillation_ICCV_2021_paper.pdf)] [[code](https://github.com/hongw579/AGKD-BML)]

+ AdvDrop: Adversarial Attack to DNNs by Dropping Information  
Ranjie DuanYuefeng Chen Dantong Niu Yun Yang A. K. Qin Yuan He  
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Duan_AdvDrop_Adversarial_Attack_to_DNNs_by_Dropping_Information_ICCV_2021_paper.pdf)] [[code]()]

+ Admix: Enhancing the Transferability of Adversarial Attacks  
Xiaosen Wang Xuanran He Jingdong Wang Kun He  
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Admix_Enhancing_the_Transferability_of_Adversarial_Attacks_ICCV_2021_paper.pdf)] [[code](https://github.com/JHL-HUST/Admix)]

+ TkML-AP: Adversarial Attacks to Top-k Multi-Label Learning  
Shu Hu, Lipeng Ke, Xin Wang, Siwei Lyu  
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Hu_TkML-AP_Adversarial_Attacks_to_Top-k_Multi-Label_Learning_ICCV_2021_paper.pdf)] [[code](https://github.com/discovershu/TKML-AP)]

+ Adversarial Example Detection Using Latent Neighborhood Graph (Defense)  
Ahmed Abusnaina, Yuhang Wu, Sunpreet Arora, Yizhen Wang, Fei Wang, Hao Yang, David Mohaisen  
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Abusnaina_Adversarial_Example_Detection_Using_Latent_Neighborhood_Graph_ICCV_2021_paper.pdf)] [[code]()]

+ Feature Importance-aware Transferable Adversarial Attacks  
Zhibo Wang, Hengchang Guo, Zhifei Zhang, Wenxin Liu, Zhan Qin, Kui Ren  
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Feature_Importance-Aware_Transferable_Adversarial_Attacks_ICCV_2021_paper.pdf)] [[code](https://github.com/hcguoO0/FIA)]

### ICLR 2020

+ NESTEROV ACCELERATED GRADIENT AND SCALE INVARIANCE FOR ADVERSARIAL ATTACKS  
Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft  
[[paper](https://arxiv.org/pdf/1908.06281.pdf)] [[code](https://github.com/JHL-HUST/SI-NI-FGSM)]

+ Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets  
Dongxian Wu, Yisen Wang, Shu-Tao Xia, James Bailey, Xingjun Ma  
[[paper](https://arxiv.org/pdf/2002.05990v1.pdf)] [[code](https://github.com/csdongxian/skip-connections-matter)]

### NIPS 2019

+ Adversarial Examples Are Not Bugs, They Are Features  
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, Aleksander Madry  
[[paper](https://arxiv.org/pdf/1905.02175.pdf)]

### CVPR 2019

+ One pixel attack for fooling deep neural networks (One_Pixel_Attack)  
Jiawei Su, Danilo Vasconcellos Vargas, Sakurai Kouichi  
[[paper](https://arxiv.org/pdf/1710.08864.pdf)] [[code](https://github.com/sarathknv/adversarial-examples-pytorch/tree/master/one_pixel_attack)]

+ Improving Transferability of Adversarial Examples with Input Diversity (DI-FGSM)  
Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou Ren, Alan Yuille  
[[paper](https://arxiv.org/pdf/1803.06978.pdf)] [[code](https://github.com/cihangxie/DI-2-FGSM)]  

+ Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks (TI-FGSM)  
Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu  
[[paper](https://arxiv.org/pdf/1904.02884.pdf)] [[code](https://github.com/dongyp13/Translation-Invariant-Attacks)]

+ SparseFool: a few pixels make a big difference (SparseFool)  
Apostolos Modas, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard Ecole Polytechnique Federale de Lausanne  
[[paper](https://arxiv.org/pdf/1811.02248.pdf)] [[code](https://github.com/LTS4/SparseFool)]



### CVPR 2018

+ Boosting Adversarial Attacks with Momentum (MI-FGSM)  
Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, Jianguo Li  
[[paper](https://arxiv.org/pdf/1705.07204.pdf)] [[code](https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks)]  

### ICLR 2018

+ Ensemble Adversarial Training: Attacks and Defenses  
Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel  
[[paper](https://arxiv.org/pdf/1705.07204.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.rfgsm)]

+ Towards Deep Learning Models Resistant to Adversarial Attacks (PGD)  
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu  
[[paper](https://arxiv.org/pdf/1706.06083.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.pgd)]  
+ Countering Adversarial Images using Input Transformations  
Chuan Guo, Mayank Rana, Moustapha Cisse, Laurens van der Maaten  
[[paper](https://arxiv.org/pdf/1711.00117.pdf)] [[code](https://github.com/facebookarchive/adversarial_image_defenses)]

### ICLR 2017

+ ADVERSARIAL EXAMPLES IN THE PHYSICAL WORLD (BIM)  
Alexey Kurakin, Ian Goodfellow, Samy Bengio  
[[paper](https://arxiv.org/pdf/1607.02533.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.bim)]

### S&P 2017

+ Towards Evaluating the Robustness of Neural Networks (C&W)  
Nicholas Carlini, David Wagner  
[[paper](https://arxiv.org/pdf/1608.04644.pdf)] [[code](https://github.com/carlini/nn_robust_attacks)]

### CVPR 2017

+ Universal adversarial perturbations (UAP)  
S. Moosavi-Dezfooli*, A. Fawzi*, O. Fawzi, P. Frossard  
[[paper](https://arxiv.org/pdf/1610.08401.pdf)] [[code](https://github.com/LTS4/universal)]

### CVPR 2016

+ DeepFool: a simple and accurate method to fool deep neural networks (Deepfool)  
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard  
[[paper](https://arxiv.org/pdf/1511.04599.pdf)] [[code](https://github.com/lts4/deepfool)]

### S&P 2016

+ The limitations of deep learning in adversarial settings (JSMA)  
Papernot, Nicolas, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, and Ananthram Swami  
[[paper](https://arxiv.org/pdf/1511.07528.pdf)]

### ICLR 2015

+ EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES (FGSM)  
Ian J. Goodfellow, Jonathon Shlens & Christian Szegedy  
[[paper](https://arxiv.org/pdf/1412.6572.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.fgsm)]

### ICLR 2014

+ Intriguing properties of neural networks (L-bfgs)  
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus  
[[paper](https://arxiv.org/pdf/1312.6199.pdf)]



---
## <span id="jump2">Image_Adversarial_Patch_Attack</span>


### ICCV 2021

+ Defending against Universal Adversarial Patches by Clipping Feature Norms (Defense)  
Cheng Yu, Jiansheng Chen, Youze Xue, Yuyang Liu, Weitao Wan, Jiayu Bao, Huimin Ma  
[[paper](https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_Defending_Against_Universal_Adversarial_Patches_by_Clipping_Feature_Norms_ICCV_2021_paper.pdf)] [[code](https://github.com/jiaxiaojunQAQ/Adv-watermark)] 

### ACM MM 2020

+ Adv-watermark: A Novel Watermark Perturbation for Adversarial Examples  
Xiaojun Jia, Xingxing Wei, Xiaochun Cao, Xiaoguang Han  
[[paper](https://arxiv.org/pdf/2008.01919.pdf)] [[code](https://github.com/jiaxiaojunQAQ/Adv-watermark)] 


### ECCV 2020

+ Adversarial Training against Location-Optimized Adversarial Patches  
Sukrut Rao, David Stutz, Bernt Schiele  
[[paper](https://arxiv.org/pdf/2005.02313.pdf)] [[code](https://github.com/sukrutrao/Adversarial-Patch-Training)]  

### ICML 2018

+ LaVAN: Localized and Visible Adversarial Noise  
Danny Karmon, Daniel Zoran, Yoav Goldberg  
[[paper](https://arxiv.org/pdf/1801.02608.pdf)] [[code]()]  

### NIPS 2017

+ Adversarial Patch  
Tom B. Brown, Dandelion Mané, , Aurko Roy, Martín Abadi, Justin Gilmer  
[[paper](https://arxiv.org/pdf/1712.09665.pdf)] [[code]()]  


## Datasets


