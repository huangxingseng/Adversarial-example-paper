--- 
## Image Adversarial Example Attack


### ArXiv 2022

+ Fast Gradient Non-sign Methods  
Yaya Cheng, Jingkuan Song, Xiaosu Zhu, Qilong Zhang, Lianli Gao, Heng Tao Shen  
[[paper](https://arxiv.org/pdf/2110.12734.pdf)] [[code](https://github.com/yaya-cheng/FGNM)]  

+ Improving Adversarial Transferability with Spatial Momentum  
YGuoqiu Wang, Xingxing Wei, Huanqian Yan  
[[paper](https://arxiv.org/pdf/2203.13479.pdf)] [[code](https://github.com/yaya-cheng/FGNM)]

### CVPR 2021

+ Improving the Transferability of Adversarial Samples With Adversarial Transformations  
Weibin Wu, Yuxin Su, Michael R. Lyu, Irwin King  
[[paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Improving_the_Transferability_of_Adversarial_Samples_With_Adversarial_Transformations_CVPR_2021_paper.pdf)] [[code](https://github.com/sarathknv/adversarial-examples-pytorch/tree/master/one_pixel_attack)]

+ Enhancing the Transferability of Adversarial Attacks through Variance Tuning  
Xiaosen Wang, Kun He  
[[paper](https://arxiv.org/pdf/2103.15571.pdf)] [[code](https://github.com/JHL-HUST/VT)]

+ Transferable Sparse Adversarial Attack  
Ziwen He, Wei Wang, Jing Dong, Tieniu Tan  
[[paper](https://arxiv.org/pdf/2105.14727.pdf)] [[code](https://github.com/shaguopohuaizhe/TSAA)]

### ICLR 2020

+ NESTEROV ACCELERATED GRADIENT AND SCALE INVARIANCE FOR ADVERSARIAL ATTACKS  
Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft  
[[paper](https://arxiv.org/pdf/1908.06281.pdf)] [[code](https://github.com/JHL-HUST/SI-NI-FGSM)]

+ Skip Connections Matter: On the Transferability of Adversarial Examples Generated with ResNets  
Dongxian Wu, Yisen Wang, Shu-Tao Xia, James Bailey, Xingjun Ma  
[[paper](https://arxiv.org/pdf/2002.05990v1.pdf)] [[code](https://github.com/csdongxian/skip-connections-matter)]

### NIPS 2019

+ Adversarial Examples Are Not Bugs, They Are Features  
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, Aleksander Madry  
[[paper](https://arxiv.org/pdf/1905.02175.pdf)]

### CVPR 2019

+ One pixel attack for fooling deep neural networks (One_Pixel_Attack)  
Jiawei Su, Danilo Vasconcellos Vargas, Sakurai Kouichi  
[[paper](https://arxiv.org/pdf/1710.08864.pdf)] [[code](https://github.com/sarathknv/adversarial-examples-pytorch/tree/master/one_pixel_attack)]

+ Improving Transferability of Adversarial Examples with Input Diversity (DI-FGSM)  
Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou Ren, Alan Yuille  
[[paper](https://arxiv.org/pdf/1803.06978.pdf)] [[code](https://github.com/cihangxie/DI-2-FGSM)]  

+ Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks (TI-FGSM)  
Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu  
[[paper](https://arxiv.org/pdf/1904.02884.pdf)] [[code](https://github.com/dongyp13/Translation-Invariant-Attacks)]

### CVPR 2018

+ Boosting Adversarial Attacks with Momentum (MI-FGSM)  
Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun Zhu, Xiaolin Hu, Jianguo Li  
[[paper](https://arxiv.org/pdf/1705.07204.pdf)] [[code](https://github.com/dongyp13/Non-Targeted-Adversarial-Attacks)]  

### ICLR 2018

+ Ensemble Adversarial Training: Attacks and Defenses  
Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, Patrick McDaniel  
[[paper](https://arxiv.org/pdf/1705.07204.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.rfgsm)]

+ Towards Deep Learning Models Resistant to Adversarial Attacks (PGD)  
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu  
[[paper](https://arxiv.org/pdf/1706.06083.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.pgd)]  
+ Countering Adversarial Images using Input Transformations  
Chuan Guo, Mayank Rana, Moustapha Cisse, Laurens van der Maaten  
[[paper](https://arxiv.org/pdf/1711.00117.pdf)] [[code](https://github.com/facebookarchive/adversarial_image_defenses)]

### ICLR 2017

+ ADVERSARIAL EXAMPLES IN THE PHYSICAL WORLD (BIM)  
Alexey Kurakin, Ian Goodfellow, Samy Bengio  
[[paper](https://arxiv.org/pdf/1607.02533.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.bim)]

### S&P 2017

+ Towards Evaluating the Robustness of Neural Networks (C&W)  
Nicholas Carlini, David Wagner  
[[paper](https://arxiv.org/pdf/1608.04644.pdf)] [[code](https://github.com/carlini/nn_robust_attacks)]

### CVPR 2017

+ Universal adversarial perturbations (UAP)  
S. Moosavi-Dezfooli*, A. Fawzi*, O. Fawzi, P. Frossard  
[[paper](https://arxiv.org/pdf/1610.08401.pdf)] [[code](https://github.com/LTS4/universal)]

### CVPR 2016

+ DeepFool: a simple and accurate method to fool deep neural networks (Deepfool)  
Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Pascal Frossard  
[[paper](https://arxiv.org/pdf/1511.04599.pdf)] [[code](https://github.com/lts4/deepfool)]

### S&P 2016

+ The limitations of deep learning in adversarial settings (JSMA)  
Papernot, Nicolas, Patrick McDaniel, Somesh Jha, Matt Fredrikson, Z. Berkay Celik, and Ananthram Swami  
[[paper](https://arxiv.org/pdf/1511.07528.pdf)]

### ICLR 2015

+ EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES (FGSM)  
Ian J. Goodfellow, Jonathon Shlens & Christian Szegedy  
[[paper](https://arxiv.org/pdf/1412.6572.pdf)] [[code](https://adversarial-attacks-pytorch.readthedocs.io/en/latest/attacks.html#module-torchattacks.attacks.fgsm)]

### ICLR 2014

+ Intriguing properties of neural networks (L-bfgs)  
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus  
[[paper](https://arxiv.org/pdf/1312.6199.pdf)]


--- 
## Image Adversarial Patch Attack


### ACM MM 2020

+ Adv-watermark: A Novel Watermark Perturbation for Adversarial Examples  
Xiaojun Jia, Xingxing Wei, Xiaochun Cao, Xiaoguang Han  
[[paper](https://arxiv.org/pdf/2008.01919.pdf)] [[code](https://github.com/jiaxiaojunQAQ/Adv-watermark)] 


## ECCV 2020

+ Adversarial Training against Location-Optimized Adversarial Patches  
Sukrut Rao, David Stutz, Bernt Schiele  
[[paper](https://arxiv.org/pdf/2005.02313.pdf)] [[code](https://github.com/sukrutrao/Adversarial-Patch-Training)]  

## ICML 2018

+ LaVAN: Localized and Visible Adversarial Noise  
Danny Karmon, Daniel Zoran, Yoav Goldberg  
[[paper](https://arxiv.org/pdf/1801.02608.pdf)] [[code]()]  

## NIPS 2017

+ Adversarial Patch  
Tom B. Brown, Dandelion Mané, , Aurko Roy, Martín Abadi, Justin Gilmer  
[[paper](https://arxiv.org/pdf/1712.09665.pdf)] [[code]()]  


## Datasets

<!-- + Reducing the Annotation Effort for Video Object Segmentation Datasets. (WACV 2021)  
Paul Voigtlaender, Lishu Luo, Chun Yuan, Yong Jiang, Bastian Leibe.  
[[paper](https://arxiv.org/pdf/2011.01142.pdf)] [[project](https://www.vision.rwth-aachen.de/page/taovos)]
-->
+ **VisDrone**: "Vision Meets Drones: Past, Present and Future". arXiv 2020.  
Pengfei Zhu, Longyin Wen, Dawei Du, Xiao Bian, Qinghua Hu, Haibin Ling   
[[paper](https://arxiv.org/abs/2001.06303)] [[project](http://aiskyeye.com/)] 
